<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>DABS</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="apple-touch-icon" sizes="180x180" href="favicon/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">
		<link rel="manifest" href="favicon/site.webmanifest">
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<script src="https://kit.fontawesome.com/ef70c722a8.js" crossorigin="anonymous"></script>
		<!-- Global site tag (gtag.js) - Google Analytics -->
		<script async src="https://www.googletagmanager.com/gtag/js?id=G-ERC7L4HM6Y"></script>
		<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'G-ERC7L4HM6Y');
		</script>
	</head>
	<body class="is-preload">

		<!-- Sidebar -->
			<section id="sidebar">
				<div class="inner">
					<nav>
						<ul>
							<li><a href="#intro">Overview</a></li>
							<li><a href="#one">How it works</a></li>
							<li><a href="#two">Domains</a></li>
							<li><a href="#three">Citation</a></li>
						</ul>
					</nav>
				</div>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Intro -->
					<section id="intro" class="wrapper style1 fullscreen fade-up">
						<div class="inner">
							<h1>DABS</h1>
							<p class="header">The <strong>D</strong>omain <strong>A</strong>gnostic <strong>B</strong>enchmark for <strong>S</strong>elf-supervised learning.</p>
							<hr class="major">
							<p class="small" >In recent years, the advent of self-supervised learning (SSL) has driven substantial progress in the field of artificial intelligence. By extracting meaningful features from unlabeled data, SSL algorithms grant models access to the troves of information produced by modern society. Unfortunately, existing algorithms are specific to individual domains (BERT for natural language processing, SimCLR for computer vision, etc.). This greatly reduces the impact and reach of SSL, as each domain requires attention from the research community to develop a tailor-made solution. To encourage research of domain-agnostic SSL models that function out-of-the box on a variety of problems, we present DABS, the domain-agnostic benchmark for self supervised learning. </p>
							<ul class="actions">
								</li><li><a href="#one" class="button">Read the Paper</a></li>
								<li><a href="https://github.com/alextamkin/domain_agnostic_benchmark" class="button">See the Code</a></li>
								<li><a href="team.html" class="button">Meet the Team</a></li>
							</ul>
						</div>
					</section>

				<!-- One -->
					<section id="one" class="wrapper style2 spotlights">
						<section>
							<a class="image"><img src="images/Pic01.jpg" alt="" data-position="center center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Embedding</h2>
									<p>First, data from pretraining datasets are embedded into vectors of uniform shape in order to allow for a domain-agnostic model architecture that does not depend on the shape of the data within each domain. We encourage the use of our provided embedding module, but participants may also create their own.</p>
									<ul class="actions">
									</ul>
								</div>
							</div>
						</section>
						<section>
							<a class="image"><img src="images/Pic02.jpg" alt="" data-position="top center" /></a>
							<div class="content">
								<div class="inner">
									<h2>Pretraining</h2>
									<p>Participants have agency over the pretraining objective they choose, and the entire architecture of their model. The goal is to use pretraining datasets to condition a model that is performant accross transfer datasets within a domain, and ultimately to create an architecture and pretraining objective that is performant in this way accross all six domains.</p>
									<ul class="actions">
									
									</ul>
								</div>
							</div>
						</section>
						<section>
							<a class="image"><img src="images/Pic03.jpg" alt="" data-position="25% 25%" /></a>
							<div class="content">
								<div class="inner">
									<h2>Transfer Learning</h2>
									<p>In the adaptation layer, the model is given labeled data in the same domain as the pretraining data, but possibly from a different dataset and with a different end task. A linear classifier is provided as the adaptation layer in our baseline model, but participants may choose their own adaptation method so long as it is in the spirit of the benchmark.</p>
									<ul class="actions">
										<!-- <li><a href="generic.html" class="button">Learn more</a></li> -->
									</ul>
								</div>
							</div>
						</section>
					</section>

				<!-- Two -->
					<section id="two" class="wrapper style3 fade-up">
						<div class="inner">
							<h2>Domains</h2>
							<p>We use six domains in order to capture performance over both traditional ML tasks that have extensive research communities (e.g. computer vision and NLP) and less studied/emerging focal point of the field (e.g. sensor and x-ray data). More information about selection criteria and specific datasets can be found in the DABS paper.</p>
							<p>Select a domain to view more information about the datasets used.</p>
							<div class="features">
								<section class="domain" data-link="/domains/images.html">
									<span class="icon solid major fa-image"></span>
									<h3>Natural Images</h3>
									<p>Pretraining is done on the ImageNet dataset, and then transfer tasks cover a wide variety of natural image classification tasks.</p>
									<span><em>Press to learn more</em></span>
								</section>
								<section class="domain" data-link="/domains/speech.html">
									<span class="icon solid major fa-comments"></span>
									<h3>Speech Recordings</h3>
									<p>Pretraining is done on the Librispeech corpus, a large dataset of English speech recordings. Downstream tasks cover everything from speaker recognition to utterance classification.</p>
									<span><em>Press to learn more</em></span>
								</section>
								<section class="domain" data-link="/domains/text.html">
										<span class="icon solid major fa-font"></span>
										<h3>Text</h3>
										<p>Natural Language Processing has among the largest machine learning communities. By including coverage of this domain, which is structurally different from the other domains, we hope to discover more powerful algorithms.</p>
										<span><em>Press to learn more</em></span>
									</section>
								<section class="domain" data-link="/domains/sensor.html">
									<span class="icon solid major fa-running"></span>
									<h3>Sensor</h3>
									<p>Pretraining and transfer tasks are both derived from the PAMAP-2 dataset, a dataset consisting of readings from many body sensors over time, and labels describing the task the monitered people were doing at the time of measurement.</p>
									<span><em>Press to learn more</em></span>
								</section>
								<section class="domain" data-link="/domains/x-ray.html">
									<span class="icon solid major fa-x-ray"></span>
									<h3>Chest X-ray</h3>
									<p> For both pretraining and transfer tasks, we use the CheXpert dataset, which contain chest X-rays labeled with the particular conditions identafiable in each by human pathologists.</p>
									<span><em>Press to learn more</em></span>
								</section>
								<section class="domain" data-link="/domains/paired.html">
									<span class="icon major fa-file-image"></span>
									<h3>Images with paired Text captions</h3>
									<p>To attain coverage of multimodal domains, we include captioned images. Pretraining is done on the COCO dataset, with downstream transfer performance assessed by the Visual Question Answering task.</p>
									<span><em>Press to learn more</em></span>
								</section>
								<section class="domain" data-link="/domains/languages.html">
									<span class="icon solid major fa-language"></span>
									<h3>Multi-language Text</h3>
									<p>In order to encourage the production of models that function accross cultural lines, we use the multilingual mC4 dataset for pretraining in the text domain, and the PAWS-X multilingual paraphrase detection tasks for transfer tasks.</p>
									<span><em>Press to learn more</em></span>
								</section>
								<section class="visibledesktop" class="domain" style="text-align: center;" data-link="#one">
									<h1 style="margin-right: 1em; margin-top: 0.5em;font-size: 5em; color: rgba(255, 255, 255, 0.35);">DABS</h1>
								</section>
							</div>
							<p>For information about dataset usage, and data origins, please see the appendix of the <a>DABS paper.</a></p>
						</div>
					</section>
					<script type="text/javascript">
						$(document).ready(function() {
							$(".domain").click(function() {
								window.location = window.location.href.slice(0, window.location.href.indexOf("/index.html")) + $(this).data('link')
							});
						});
					</script>

				<!-- Three -->
					<section id="three" class="wrapper style1 fade-up">
						<div class="inner">
							<h2>Using DABS?</h2>
							<p>We appreciate your desire to contribute or build on DABS! We only ask that you cite our paper when doing so. You may use the bibtex snippet below to cite our work.</p> 
							<br>
							<pre><code>
@techreport{WahCUB_200_2011,
	Title = {{The Caltech-UCSD Birds-200-2011 Dataset}},
	Author = {Wah, C. and Branson, S. and Welinder, P. and Perona, P. and Belongie, S.},
	Year = {2011}
	Institution = {California Institute of Technology},
	Number = {CNS-TR-2011-001}
}
						</code></pre>
							<br>
							<br>
						</div>
					</section>


			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper style1-alt">
				<div class="inner">
					<ul class="menu">
						<a href="team.html">Contact Us</a>
						<li>DABS is released under MIT License.</li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>