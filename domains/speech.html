<!DOCTYPE HTML>
<!--
	Hyperspace by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>DABS</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<link rel="apple-touch-icon" sizes="180x180" href="../favicon/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../favicon/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../favicon/favicon-16x16.png">
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a href="../index.html" class="title">DABS</a>
				<nav>
					<ul>
						<li><a href="../index.html">Home</a></li>
						<li><a href="../team.html">Meet the Team</a></li>
					</ul>
				</nav>
			</header>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<section id="main" class="wrapper">
						<div class="inner">
							<span class="image fit"><img src="../images/domains/speech.png" alt="" /></span>
							<h1 class="major">Speech Recordings</h1>
							<h2>Pretraining</h2> 
							<div class="dataset">
								<h4>LibriSpeech</h4> 
								<p>The <a href=”http://www.openslr.org/12”>LibriSpeech</a> dataset contains approximately 1000 hours of English speech derived from audiobook readings from the Librivox project. </p>
							</div>
							<h2>Transfer</h2>
							<div class="dataset">
								<h4>VoxCeleb</h4>
								<p>The <a href=”http://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox1.html”>VoxCeleb</a> dataset includes over 150K speech samples from over 1,251 speakers. It is used for speaker identification. Each example contains the spectrogram as well as the speaker label.</p>
							</div>
							<div class="dataset">
								<h4>AudioMNIST</h4>
								<p>The <a href=”https://github.com/Jakobovski/free-spoken-digit-dataset”>AudioMNIST</a> spoken digit dataset contains 2,500 recordings of 5 speakers reading out different digits in English . The recordings are in wav files at 8kHz and are trimmed to minimize silence at the beginning and end. Each sample contains the spectrogram and a label indicating the digit spoken.</p>
							</div>
							<div class="dataset">
								<h4>Speech Commands</h4>
								<p>The <a href=”https://arxiv.org/abs/1804.03209”>Speech Commands</a> dataset is intended for simple keyword detection useful in building voice interfaces for applications. It was created using samples contributed from thousands of different people and contains 65,000 one second utterances of 30 short words (e.g. yes, no, up, down, on, off). Unknown utterances not identifiable as any of the keywords, and files of background noise, are also included. Each sample contains the spectrogram and label.</p>
							</div>
							<div class="dataset">
								<h4>Fluent Speech Commands</h4>
								<p>The <a href=”https://fluent.ai/fluent-speech-commands-a-dataset-for-spoken-language-understanding-research/”>Fluent Speech Commands</a> dataset was created with the goal of providing a benchmark for end-to-end spoken language understanding (SLU) models.  The data were gathered via crowdsourcing and include 30,043 utterances from 97 speakers. Each utterance is a phrase commonly used to control smart home devices or virtual assistants. Utterances are recorded as single channel 16 KHz wav files. Each utterance is labeled with action, object, and location values., We consider three separate tasks, including classifying actions ('change language', 'activate', 'deactivate', 'increase', 'decrease', 'bring') objects ('none', 'music', 'lights', 'volume', 'heat', 'lamp', 'newspaper', 'juice', 'socks', 'shoes', 'Chinese', 'Korean', 'English', 'German'), and locations ( 'none', 'kitchen', 'bedroom', 'washroom’).</p>
							</div>
							<div class="dataset">
								<h4>LibriSpeech</h4> 
								<p>The <a href=”http://www.openslr.org/12”>LibriSpeech</a> dataset contains approximately 1000 hours of English speech derived from audiobook readings from the Librivox project. </p>
							</div>
							<a href="../citations/speech.html"  style="margin-left: 20px;" class="button" >Cite Datasets</a>
						</div>
					</section>

			</div>

		<!-- Footer -->
			<footer id="footer" class="wrapper alt">
				<div class="inner">
					<ul class="menu">
						<li>DABS is released under MIT License.</li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>